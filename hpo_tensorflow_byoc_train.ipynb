{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker - Bring Your Own Container¶\n",
    "### 学習用インスタンスでの学習\n",
    "ここでは TensorFlow を使ったサンプルコードを題材に、Amazon SageMaker で独自コンテナを用いた機械学習モデルの学習方法を順を追って説明します。トレーニングスクリプトは既に SageMaker 向けに書き換えられた形で準備され、その上で、独自の学習用コンテナを活用します。 トレーニングスクリプトを SageMaker 向けに書き換える際は [Bring Your Own Model ハンズオンワークショップ](https://github.com/aws-samples/amazon-sagemaker-examples-jp/tree/master/workshop/lab_bring-your-own-model) をご参考に下さい。\n",
    "\n",
    "また本ハンズオンで活用するデータは、[Bring Your Own Container のためのデータ準備](https://github.com/tkazusa/data_prep.ipynb)をお使い下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -t sm-tf-nightly-gpu container/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習用インスタンスを用いた学習\n",
    "### ECR への Docker イメージの登録\n",
    "build した Docker イメージを Docker コンテナレジストリである Amazon ECR へ登録することで、SageMaker の学習時に活用できるようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# boto3の機能を使ってリポジトリ名に必要な情報を取得する\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "tag = ':latest'\n",
    "\n",
    "ecr_repository = 'sm-tf-nightly-gpu'\n",
    "image_uri = '{}.dkr.ecr.{}.amazonaws.com/{}'.format(account_id, region, ecr_repository + tag)\n",
    "\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    " \n",
    "# リポジトリの作成\n",
    "# すでにある場合はこのコマンドは必要ない\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    " \n",
    "!docker build -t word2vec .\n",
    "!docker tag {ecr_repository + tag} $image_uri\n",
    "!docker push $image_uri\n",
    "\n",
    "print('コンテナは {} へ登録されています。'.format(image_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU を使った学習インスタンスでの学習\n",
    "登録された Docker イメージと、S3 へアップロードされたデータを用いて学習を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import CategoricalParameter, HyperparameterTuner\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "output_path = 's3://{}/output'.format(bucket)\n",
    "data_path = {'train': 's3://{}/data'.format(bucket)}\n",
    "\n",
    "role = get_execution_role()\n",
    "hyperparameters = {'batch_size': 64,'epochs': 30}\n",
    "hyperparameter_ranges = {'optimizer': CategoricalParameter(['adam', 'sgd'])}\n",
    "objective_metric_name = 'loss'\n",
    "objective_type = 'Minimize'\n",
    "\n",
    "metric_definitions = [{'Name': 'loss',\n",
    "                       'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "                      {'Name': 'accuracy',\n",
    "                       'Regex': 'accuracy: ([0-9\\\\.]+)'}]\n",
    "\n",
    "estimator = Estimator(image_name=image_uri,\n",
    "                      role=role,\n",
    "                      hyperparameters=hyperparameters,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='ml.p3.2xlarge',\n",
    "                      output_path=output_path)\n",
    "\n",
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=2,\n",
    "                            max_parallel_jobs=1,\n",
    "                            objective_type=objective_type,\n",
    "                            early_stopping_type='Auto')\n",
    "\n",
    "\n",
    "tuner.fit(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパラチューニングジョブの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_job_name = '<job name>'\n",
    "tuning_job = sagemaker.HyperparameterTuningJobAnalytics(hpo_job_name)\n",
    "df_hpo = tuning_job.dataframe()\n",
    "\n",
    "df_hpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TuningJob 結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh\n",
    "import bokeh.io\n",
    "bokeh.io.output_notebook()\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "\n",
    "class HoverHelper():\n",
    "\n",
    "    def __init__(self, tuning_analytics):\n",
    "        self.tuner = tuning_analytics\n",
    "\n",
    "    def hovertool(self):\n",
    "        tooltips = [\n",
    "            (\"FinalObjectiveValue\", \"@FinalObjectiveValue\"),\n",
    "            (\"TrainingJobName\", \"@TrainingJobName\"),\n",
    "        ]\n",
    "        for k in self.tuner.tuning_ranges.keys():\n",
    "            tooltips.append( (k, \"@{%s}\" % k) )\n",
    "\n",
    "        ht = HoverTool(tooltips=tooltips)\n",
    "        return ht\n",
    "\n",
    "    def tools(self, standard_tools='pan,crosshair,wheel_zoom,zoom_in,zoom_out,undo,reset'):\n",
    "        return [self.hovertool(), standard_tools]\n",
    "\n",
    "hover = HoverHelper(tuning_job)\n",
    "\n",
    "p = figure(plot_width=900, plot_height=400, tools=hover.tools(), x_axis_type='datetime')\n",
    "p.circle(source=df_hpo, x='TrainingStartTime', y='FinalObjectiveValue')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
